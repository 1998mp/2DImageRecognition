{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGbKnXj8Zequ",
        "outputId": "067b9928-a667-43ee-822f-78967156e523"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: NVIDIA GeForce RTX 2080 (UUID: GPU-1ccf7bf0-0779-b18f-1040-6359238365d4)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d288Z2mF5dC"
      },
      "outputs": [],
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoOhp5ABsmt9"
      },
      "source": [
        "### Some basic setup, import:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "outputs": [],
      "source": [
        "# %matplotlib inline\n",
        "\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "import glob\n",
        "# from matplotlib import pyplot as plt\n",
        "from IPython import display\n",
        "from IPython.display import Image\n",
        "# from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "\n",
        "from detectron2.checkpoint import DetectionCheckpointer\n",
        "from detectron2.modeling import build_model\n",
        "\n",
        "import IPython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA4U08qHshSs"
      },
      "source": [
        "Set seed for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFjEIXlFfYRg"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "np.random.seed(seed=SEED)\n",
        "torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh2cizYCtyU0"
      },
      "outputs": [],
      "source": [
        "def imshow(img):\n",
        "    _, ret = cv2.imencode('.jpg', img) \n",
        "    i = IPython.display.Image(data=ret)\n",
        "    IPython.display.display(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2bjrfb2LDeo"
      },
      "source": [
        "# Train on a custom dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjbUIhSxUdm_"
      },
      "source": [
        "\n",
        "## Prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vsy4HuCcj7E2"
      },
      "outputs": [],
      "source": [
        "# dataset_name = \"my_dataset_train\"\n",
        "# metadata = {}\n",
        "# json_file = \"path_to_.json\"\n",
        "# image_root = \"path_to_image_root\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7xTcylhbN2t"
      },
      "outputs": [],
      "source": [
        "# register_coco_instances(dataset_name, metadata, json_file, image_root)\n",
        "# metadata = MetadataCatalog.get(dataset_name)\n",
        "# dataset_dicts = DatasetCatalog.get(dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"BigScrewScrewWasher\"\n",
        "metadata = {}\n",
        "json_file = \"./data/screwwasherANDbigscrew/result.json\"\n",
        "image_root = \"./data/screwwasherANDbigscrew\"\n",
        "\n",
        "register_coco_instances(dataset_name, metadata, json_file, image_root)\n",
        "metadata = MetadataCatalog.get(dataset_name)\n",
        "dataset_dicts = DatasetCatalog.get(dataset_name)"
      ],
      "metadata": {
        "id": "DTXpZqXeI2uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset_name = \"BigScrewScrewWasherValid\"\n",
        "val_metadata = {}\n",
        "val_json_file = \"./data/screwwasherANDbigscrewvalid/result.json\"\n",
        "val_image_root = \"./data/screwwasherANDbigscrewvalid\"\n",
        "\n",
        "register_coco_instances(val_dataset_name, val_metadata, val_json_file, val_image_root)\n",
        "val_metadata = MetadataCatalog.get(val_dataset_name)\n",
        "val_dataset_dicts = DatasetCatalog.get(val_dataset_name)"
      ],
      "metadata": {
        "id": "U245VvekI4m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"GlassMetalPaperPlasticAndShowroom\"\n",
        "metadata = {}\n",
        "json_file = \"./data/GlassMetalPaperPlasticAndShowroom/result.json\"\n",
        "image_root = \"./data/GlassMetalPaperPlasticAndShowroom\"\n",
        "\n",
        "register_coco_instances(dataset_name, metadata, json_file, image_root)\n",
        "metadata = MetadataCatalog.get(dataset_name)\n",
        "dataset_dicts = DatasetCatalog.get(dataset_name)"
      ],
      "metadata": {
        "id": "Z7uWWuA4I7mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset_name = \"GlassMetalPaperPlasticAndShowroomValid\"\n",
        "val_metadata = {}\n",
        "val_json_file = \"./data/GlassMetalPaperPlasticAndShowroomValid/result.json\"\n",
        "val_image_root = \"./data/GlassMetalPaperPlasticAndShowroomValid\"\n",
        "\n",
        "register_coco_instances(val_dataset_name, val_metadata, val_json_file, val_image_root)\n",
        "val_metadata = MetadataCatalog.get(val_dataset_name)\n",
        "val_dataset_dicts = DatasetCatalog.get(val_dataset_name)"
      ],
      "metadata": {
        "id": "Jp-NlBYXI7fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"glassMetalPapperPlastic\"\n",
        "metadata = {}\n",
        "json_file = \"./data/glassMetalPapperPlastic/result.json\"\n",
        "image_root = \"./data/glassMetalPapperPlastic\"\n",
        "\n",
        "register_coco_instances(dataset_name, metadata, json_file, image_root)\n",
        "metadata = MetadataCatalog.get(dataset_name).set(thing_classes=[\"Glass\", \"Metal\", \"Paper\", \"Plastic\"])\n",
        "dataset_dicts = DatasetCatalog.get(dataset_name)"
      ],
      "metadata": {
        "id": "050tsqa9JN4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset_name = \"valid25\"\n",
        "val_metadata = {}\n",
        "val_json_file = \"./data/valid25/result.json\"\n",
        "val_image_root = \"./data/valid25\"\n",
        "\n",
        "register_coco_instances(val_dataset_name, val_metadata, val_json_file, val_image_root)\n",
        "val_metadata = MetadataCatalog.get(val_dataset_name).set(thing_classes=[\"Glass\", \"Metal\", \"Paper\", \"Plastic\"])\n",
        "val_dataset_dicts = DatasetCatalog.get(val_dataset_name)"
      ],
      "metadata": {
        "id": "voKfouv_JdRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"showroom\"\n",
        "metadata = {}\n",
        "json_file = \"./data/showroom/result.json\"\n",
        "image_root = \"./data/showroom\"\n",
        "\n",
        "register_coco_instances(dataset_name, metadata, json_file, image_root)\n",
        "metadata = MetadataCatalog.get(dataset_name)\n",
        "dataset_dicts = DatasetCatalog.get(dataset_name)"
      ],
      "metadata": {
        "id": "8ClvB2XFJNyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset_name = \"showroomvalid\"\n",
        "val_metadata = {}\n",
        "val_json_file = \"./data/showroomvalid/result.json\"\n",
        "val_image_root = \"./data/showroomvalid\"\n",
        "\n",
        "register_coco_instances(val_dataset_name, val_metadata, val_json_file, val_image_root)\n",
        "val_metadata = MetadataCatalog.get(val_dataset_name)\n",
        "val_dataset_dicts = DatasetCatalog.get(val_dataset_name)"
      ],
      "metadata": {
        "id": "LeM4O77AJd_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d6tkUXbmmtK"
      },
      "outputs": [],
      "source": [
        "def random_sample(dataset_dicts, number, metadata):\n",
        "    for d in random.sample(dataset_dicts, number):\n",
        "        img = cv2.imread(d[\"file_name\"])\n",
        "        visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=0.5)\n",
        "        vis = visualizer.draw_dataset_dict(d)\n",
        "        imshow(vis.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP0RODGMtyU_"
      },
      "outputs": [],
      "source": [
        "random_sample(dataset_dicts, 5, metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlqXIXXhW8dA"
      },
      "source": [
        "## Train\n",
        "\n",
        "Now, let's fine-tune a COCO-pretrained R50-FPN Mask R-CNN model on the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pB3e3EYgoG7J"
      },
      "outputs": [],
      "source": [
        "def train(dataset_name, \n",
        "          images_per_batch=2, \n",
        "          learning_rate=0.00025, \n",
        "          iteration=300, \n",
        "          batch_size_per_image=512, \n",
        "          num_classes=1, \n",
        "          test=False, \n",
        "          test_dataset_name=\"\",\n",
        "          init_model=\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\",\n",
        "          retinaNet=False):\n",
        "    \n",
        "    cfg = get_cfg()\n",
        "    \n",
        "    # minimum image size for the train set\n",
        "    cfg.INPUT.MIN_SIZE_TRAIN = (512,)\n",
        "    # maximum image size for the train set\n",
        "    cfg.INPUT.MAX_SIZE_TRAIN = 512\n",
        "    # minimum image size for the test set\n",
        "    cfg.INPUT.MIN_SIZE_TEST = 512\n",
        "    # maximum image size for the test set\n",
        "    cfg.INPUT.MAX_SIZE_TEST = 512\n",
        "\n",
        "\n",
        "    # cfg.MODEL.DEVICE='cpu'\n",
        "\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(init_model))\n",
        "    cfg.DATASETS.TRAIN = (dataset_name,)\n",
        "\n",
        "    if test:\n",
        "        cfg.DATASETS.TEST = (test_dataset_name,)\n",
        "    else:\n",
        "        cfg.DATASETS.TEST = ()\n",
        "\n",
        "    cfg.DATALOADER.NUM_WORKERS = 2\n",
        "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(init_model)  # Let training initialize from model zoo\n",
        "    cfg.SOLVER.IMS_PER_BATCH = images_per_batch  # This is the real \"batch size\" commonly known to deep learning people (number of images per batch)\n",
        "    cfg.SOLVER.BASE_LR = learning_rate  \n",
        "    cfg.SOLVER.MAX_ITER = iteration\n",
        "    cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = batch_size_per_image   # The \"RoIHead batch size\". 128 is faster, (default: 512). Number of regions per image used to train RPN.\n",
        "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes  \n",
        "    \n",
        "    if retinaNet:\n",
        "        cfg.MODEL.RETINANET.NUM_CLASSES = num_classes\n",
        "    \n",
        "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "    trainer = DefaultTrainer(cfg) \n",
        "    trainer.resume_or_load(resume=False)\n",
        "    trainer.train()\n",
        "\n",
        "    if test:\n",
        "        cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "        predictor = DefaultPredictor(cfg)\n",
        "        evaluator = COCOEvaluator(test_dataset_name, output_dir=\"./output\")\n",
        "        test_result = trainer.test(cfg, predictor.model, evaluator)\n",
        "        return cfg, test_result\n",
        "\n",
        "    return cfg, \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcrJoNeXrzUb"
      },
      "outputs": [],
      "source": [
        "cfg, test_result = train(dataset_name, \n",
        "                         images_per_batch=2, \n",
        "                         learning_rate=0.00025, \n",
        "                         iteration=3000, \n",
        "                         batch_size_per_image=128, \n",
        "                         num_classes=1, \n",
        "                         test=True, \n",
        "                         test_dataset_name=val_dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNWuyAcU0BMB"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(test_result, columns=test_result.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdguXTIn0OU2"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e4vdDIOXyxF"
      },
      "source": [
        "## Inference & evaluation using the trained model\n",
        "Let's run inference with the trained model on the validation dataset. First, let's create a predictor using the model we just trained:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ya5nEuMELeq8"
      },
      "outputs": [],
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJHEvtFgqVim"
      },
      "outputs": [],
      "source": [
        "evaluator = COCOEvaluator(\"val_glass3\", output_dir=\"./output\")\n",
        "val_loader = build_detection_test_loader(cfg, \"val_glass3\")\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWd5DP8V0eo3"
      },
      "outputs": [],
      "source": [
        "def evaluate(image, metadata, instance_mode=False):\n",
        "    im = cv2.imread(image)\n",
        "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "    \n",
        "    v = {}\n",
        "    if instance_mode:\n",
        "        v = Visualizer(im[:, :, ::-1],\n",
        "                        metadata=metadata, \n",
        "                        scale=0.5, \n",
        "                        instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
        "        )\n",
        "    else:\n",
        "        v = Visualizer(im[:, :, ::-1],\n",
        "                        metadata=metadata, \n",
        "                        scale=0.5,\n",
        "        )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hY_XGTd1uRYh"
      },
      "outputs": [],
      "source": [
        "evaluate(\"/content/drive/MyDrive/Detectron/data/dataset-resized/glass/test/glass451.jpg\", metadata, instance_mode=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9v-7Oq6uRuZ"
      },
      "outputs": [],
      "source": [
        "evaluate(\"/content/drive/MyDrive/Detectron/data/dataset-resized/glass/test/glass451.jpg\", metadata, instance_mode=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOqK4tJ50kLt"
      },
      "outputs": [],
      "source": [
        "def random_test_sample(dataset_dicts, number, metadata, instance_mode=False):\n",
        "    for i in range(number):\n",
        "        images = glob.glob(dataset_dicts + \"*.jpg\")\n",
        "        random_image = random.choice(images)\n",
        "        evaluate(random_image, metadata, instance_mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoViowC80jm_"
      },
      "outputs": [],
      "source": [
        "test_dataset_path = \"/content/drive/MyDrive/Detectron/data/dataset-resized/glass/test/\"\n",
        "random_test_sample(test_dataset_path, 5, metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-AFfIYKq-Sl"
      },
      "source": [
        "## Automation of training, parameter setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pu64mLX2tyWX"
      },
      "outputs": [],
      "source": [
        "def get_best_result(df, number=3, segmentation=True):\n",
        "    dfbbox = df.loc[df['Result-type'] == \"bbox\"].sort_values(by='AP', ascending=False).head(number)\n",
        "    if segmentation:\n",
        "        dfsegm = df.loc[df['Result-type'] == \"segm\"].sort_values(by='AP', ascending=False).head(number)\n",
        "        return dfbbox, dfsegm\n",
        "    else:\n",
        "        return dfbbox"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_result(result, model_name, segmentation=True):\n",
        "    df = pd.DataFrame()\n",
        "    for i in range(len(result)):\n",
        "        temp = pd.DataFrame(result[i][4], columns=result[i][4].keys())\n",
        "        temp = temp.T\n",
        "\n",
        "        if segmentation:\n",
        "            images_per_batch = pd.Series([result[i][0], result[i][0]], index=[0, 1])\n",
        "            learning_rate = pd.Series([result[i][1], result[i][1]], index=[0, 1])\n",
        "            batch_size_per_image = pd.Series([result[i][2], result[i][2]], index=[0, 1])\n",
        "        else:\n",
        "            images_per_batch = pd.Series([result[i][0]], index=[0])\n",
        "            learning_rate = pd.Series([result[i][1]], index=[0])\n",
        "            batch_size_per_image = pd.Series([result[i][2]], index=[0])\n",
        "\n",
        "        temp['images_per_batch'] = images_per_batch.values\n",
        "        temp['learning_rate'] = learning_rate.values\n",
        "        temp['batch_size_per_image'] = batch_size_per_image.values\n",
        "\n",
        "        df = pd.concat([df, temp])\n",
        "        df.to_csv('result/' + str(model_name) + '.csv', index=True, index_label=\"Result-type\") "
      ],
      "metadata": {
        "id": "auaVHXaYAex7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHTML6HdrQOW"
      },
      "outputs": [],
      "source": [
        "# images_per_batch = [2, 4, 8, 16, 32, 64]\n",
        "# learning_rate = [0.01, 0.0025, 0.001, 0.00025, 0.0001, 0.000025, 0.00001]\n",
        "# batch_size_per_image = [128, 256, 512] \n",
        "# iteration = 300\n",
        "# num_classes = 4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# init_model=\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\""
      ],
      "metadata": {
        "id": "WK3HSrzt_16_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# result = []\n",
        "# for ipb in images_per_batch:\n",
        "#     for lr in learning_rate:\n",
        "#         for bspi in batch_size_per_image:\n",
        "#             cfg, test_result = train(dataset_name, \n",
        "#                                      images_per_batch=ipb, \n",
        "#                                      learning_rate=lr, \n",
        "#                                      iteration=iteration, \n",
        "#                                      batch_size_per_image=bspi, \n",
        "#                                      num_classes=num_classes, \n",
        "#                                      test=True, \n",
        "#                                      test_dataset_name=val_dataset_name,\n",
        "#                                      init_model=init_model)\n",
        "\n",
        "#             result.append([ipb, lr, bspi, cfg, test_result])\n",
        "#             save_result(result=result, model_name=\"mask_rcnn_R_50_FPN_3x\", segmentation=True)"
      ],
      "metadata": {
        "id": "PAqCOhPB_qx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqg3rTcDrQaz"
      },
      "outputs": [],
      "source": [
        "# df = pd.DataFrame()\n",
        "# for i in range(len(result)):\n",
        "#     temp = pd.DataFrame(result[i][4], columns=result[i][4].keys())\n",
        "#     temp = temp.T\n",
        "\n",
        "#     images_per_batch = pd.Series([result[i][0], result[i][0]], index=[0, 1])\n",
        "#     learning_rate = pd.Series([result[i][1], result[i][1]], index=[0, 1])\n",
        "#     batch_size_per_image = pd.Series([result[i][2], result[i][2]], index=[0, 1])\n",
        "\n",
        "#     temp['images_per_batch'] = images_per_batch.values\n",
        "#     temp['learning_rate'] = learning_rate.values\n",
        "#     temp['batch_size_per_image'] = batch_size_per_image.values\n",
        "\n",
        "#     df = pd.concat([df, temp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yv9hT397reHk"
      },
      "outputs": [],
      "source": [
        "# df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV6nzbzctyWZ"
      },
      "source": [
        "### Instance Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GRKtD28tyWa"
      },
      "outputs": [],
      "source": [
        "# import gc\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rh_-foZBtyWa"
      },
      "outputs": [],
      "source": [
        "# t = torch.cuda.get_device_properties(0).total_memory\n",
        "# r = torch.cuda.memory_reserved(0)\n",
        "# a = torch.cuda.memory_allocated(0)\n",
        "# f = r-a  # free inside reserved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYvdTdKjtyWa"
      },
      "outputs": [],
      "source": [
        "# f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0YEpC_ctyWb"
      },
      "source": [
        "#### COCO-pretrained R50-FPN Mask R-CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAGjwKM0tyWc"
      },
      "outputs": [],
      "source": [
        "images_per_batch = [64, 32, 16, 8, 4, 2]\n",
        "# images_per_batch = [16, 8, 4, 2]\n",
        "learning_rate = [0.01, 0.0025, 0.001, 0.00025, 0.0001, 0.000025, 0.00001]\n",
        "batch_size_per_image = [128, 256, 512] \n",
        "iteration = 1500\n",
        "num_classes = 4\n",
        "# num_classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0nF9YkGtyWc"
      },
      "outputs": [],
      "source": [
        "init_model=\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydeY8JWttyWc"
      },
      "outputs": [],
      "source": [
        "result = []\n",
        "for ipb in images_per_batch:\n",
        "    for lr in learning_rate:\n",
        "        for bspi in batch_size_per_image:\n",
        "            cfg, test_result = train(dataset_name, \n",
        "                                     images_per_batch=ipb, \n",
        "                                     learning_rate=lr, \n",
        "                                     iteration=iteration, \n",
        "                                     batch_size_per_image=bspi, \n",
        "                                     num_classes=num_classes, \n",
        "                                     test=True, \n",
        "                                     test_dataset_name=val_dataset_name,\n",
        "                                     init_model=init_model)\n",
        "\n",
        "            result.append([ipb, lr, bspi, cfg, test_result])\n",
        "            save_result(result=result, model_name=\"mask_rcnn_R_50_FPN_3x\", segmentation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PE0r5p78tyWd"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "for i in range(len(result)):\n",
        "    temp = pd.DataFrame(result[i][4], columns=result[i][4].keys())\n",
        "    temp = temp.T\n",
        "\n",
        "    images_per_batch = pd.Series([result[i][0], result[i][0]], index=[0, 1])\n",
        "    learning_rate = pd.Series([result[i][1], result[i][1]], index=[0, 1])\n",
        "    batch_size_per_image = pd.Series([result[i][2], result[i][2]], index=[0, 1])\n",
        "\n",
        "    temp['images_per_batch'] = images_per_batch.values\n",
        "    temp['learning_rate'] = learning_rate.values\n",
        "    temp['batch_size_per_image'] = batch_size_per_image.values\n",
        "\n",
        "    df = pd.concat([df, temp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QfWC7rQtyWd"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuI2TluztyWe"
      },
      "outputs": [],
      "source": [
        "df.to_csv('result2/mask_rcnn_R_50_FPN_3x.csv', index=True, index_label=\"Result-type\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "181lS9BityWe"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv('result/mask_rcnn_R_50_FPN_3x.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6F0zIfEtyWf"
      },
      "outputs": [],
      "source": [
        "dfbbox, dfsegm = get_best_result(df2, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huiUgpkotyWf"
      },
      "outputs": [],
      "source": [
        "dfbbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwwQFwWPtyWf"
      },
      "outputs": [],
      "source": [
        "dfsegm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M7_ychQtyWg"
      },
      "source": [
        "#### COCO-pretrained R101-FPN Mask R-CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sh8H67styWg"
      },
      "outputs": [],
      "source": [
        "images_per_batch = [2, 4, 8, 16, 32, 64]\n",
        "# images_per_batch = [2, 4, 8]\n",
        "learning_rate = [0.01, 0.0025, 0.001, 0.00025, 0.0001, 0.000025, 0.00001]\n",
        "batch_size_per_image = [128, 256, 512] \n",
        "iteration = 1500\n",
        "num_classes = 4\n",
        "# num_classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qApLq9cJtyWg"
      },
      "outputs": [],
      "source": [
        "init_model=\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saq4vpaWtyWh"
      },
      "outputs": [],
      "source": [
        "result = []\n",
        "for ipb in images_per_batch:\n",
        "    for lr in learning_rate:\n",
        "        for bspi in batch_size_per_image:\n",
        "            cfg, test_result = train(dataset_name, \n",
        "                                     images_per_batch=ipb, \n",
        "                                     learning_rate=lr, \n",
        "                                     iteration=iteration, \n",
        "                                     batch_size_per_image=bspi, \n",
        "                                     num_classes=num_classes, \n",
        "                                     test=True, \n",
        "                                     test_dataset_name=val_dataset_name,\n",
        "                                     init_model=init_model)\n",
        "\n",
        "            result.append([ipb, lr, bspi, cfg, test_result])\n",
        "            save_result(result=result, model_name=\"mask_rcnn_R_101_FPN_3x\", segmentation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBz54mwltyWh"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "for i in range(len(result)):\n",
        "    temp = pd.DataFrame(result[i][4], columns=result[i][4].keys())\n",
        "    temp = temp.T\n",
        "\n",
        "    images_per_batch = pd.Series([result[i][0], result[i][0]], index=[0, 1])\n",
        "    learning_rate = pd.Series([result[i][1], result[i][1]], index=[0, 1])\n",
        "    batch_size_per_image = pd.Series([result[i][2], result[i][2]], index=[0, 1])\n",
        "\n",
        "    temp['images_per_batch'] = images_per_batch.values\n",
        "    temp['learning_rate'] = learning_rate.values\n",
        "    temp['batch_size_per_image'] = batch_size_per_image.values\n",
        "\n",
        "    df = pd.concat([df, temp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5exQsuBItyWi"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pF5x2djtyWl"
      },
      "outputs": [],
      "source": [
        "df.to_csv('result2/mask_rcnn_R_101_FPN_3x.csv', index=True, index_label=\"Result-type\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXkvjmiwtyWl"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv('result/mask_rcnn_R_101_FPN_3x.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jM5lUOV1tyWm"
      },
      "outputs": [],
      "source": [
        "dfbbox, dfsegm = get_best_result(df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOb2bKn7tyWm"
      },
      "outputs": [],
      "source": [
        "dfbbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1nDnzRBtyWm"
      },
      "outputs": [],
      "source": [
        "dfsegm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CELsQtS7jThy"
      },
      "source": [
        "### Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vrvJiK6iwTA"
      },
      "source": [
        "#### COCO-pretrained R50-FPN Faster R-CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESDjeWvPtyWm"
      },
      "outputs": [],
      "source": [
        "images_per_batch = [2, 4, 8, 16, 32, 64]\n",
        "# images_per_batch = [2, 4, 8]\n",
        "learning_rate = [0.01, 0.0025, 0.001, 0.00025, 0.0001, 0.000025, 0.00001]\n",
        "batch_size_per_image = [128, 256, 512] \n",
        "iteration = 1500\n",
        "num_classes = 4\n",
        "# num_classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-a9OozTjhll"
      },
      "outputs": [],
      "source": [
        "init_model=\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fEI824rknpl"
      },
      "outputs": [],
      "source": [
        "result = []\n",
        "for ipb in images_per_batch:\n",
        "    for lr in learning_rate:\n",
        "        for bspi in batch_size_per_image:\n",
        "            cfg, test_result = train(dataset_name, \n",
        "                                     images_per_batch=ipb, \n",
        "                                     learning_rate=lr, \n",
        "                                     iteration=iteration, \n",
        "                                     batch_size_per_image=bspi, \n",
        "                                     num_classes=num_classes, \n",
        "                                     test=True, \n",
        "                                     test_dataset_name=val_dataset_name,\n",
        "                                     init_model=init_model)\n",
        "\n",
        "            result.append([ipb, lr, bspi, cfg, test_result])\n",
        "            save_result(result=result, model_name=\"faster_rcnn_R_50_FPN_3x\", segmentation=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmNxR3bfkvt9"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "for i in range(len(result)):\n",
        "    temp = pd.DataFrame(result[i][4], columns=result[i][4].keys())\n",
        "    temp = temp.T\n",
        "\n",
        "    images_per_batch = pd.Series([result[i][0]], index=[0])\n",
        "    learning_rate = pd.Series([result[i][1]], index=[0])\n",
        "    batch_size_per_image = pd.Series([result[i][2]], index=[0])\n",
        "\n",
        "    temp['images_per_batch'] = images_per_batch.values\n",
        "    temp['learning_rate'] = learning_rate.values\n",
        "    temp['batch_size_per_image'] = batch_size_per_image.values\n",
        "\n",
        "    df = pd.concat([df, temp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duBUFyGMk0T2"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyMWnYeyk8SH"
      },
      "outputs": [],
      "source": [
        "df.to_csv('result2/faster_rcnn_R_50_FPN_3x.csv', index=True, index_label=\"Result-type\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm9jN75jtyWo"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv('result/faster_rcnn_R_50_FPN_3x.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ua8u0SYatyWp"
      },
      "outputs": [],
      "source": [
        "dfbbox = get_best_result(df2, 5, segmentation=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOOd2cyatyWp"
      },
      "outputs": [],
      "source": [
        "dfbbox"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKPAnihfi2pY"
      },
      "source": [
        "#### COCO-pretrained R101-FPN Faster R-CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHuwIulctyWp"
      },
      "outputs": [],
      "source": [
        "images_per_batch = [2, 4, 8, 16, 32, 64]\n",
        "# images_per_batch = [2, 4, 8]\n",
        "learning_rate = [0.01, 0.0025, 0.001, 0.00025, 0.0001, 0.000025, 0.00001]\n",
        "batch_size_per_image = [128, 256, 512] \n",
        "iteration = 1500\n",
        "num_classes = 4\n",
        "# num_classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGN5KI7NjhjD"
      },
      "outputs": [],
      "source": [
        "init_model=\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjVAgeZxkoUw"
      },
      "outputs": [],
      "source": [
        "result = []\n",
        "for ipb in images_per_batch:\n",
        "    for lr in learning_rate:\n",
        "        for bspi in batch_size_per_image:\n",
        "            cfg, test_result = train(dataset_name, \n",
        "                                     images_per_batch=ipb, \n",
        "                                     learning_rate=lr, \n",
        "                                     iteration=iteration, \n",
        "                                     batch_size_per_image=bspi, \n",
        "                                     num_classes=num_classes, \n",
        "                                     test=True, \n",
        "                                     test_dataset_name=val_dataset_name,\n",
        "                                     init_model=init_model)\n",
        "\n",
        "            result.append([ipb, lr, bspi, cfg, test_result])\n",
        "            save_result(result=result, model_name=\"faster_rcnn_R_101_FPN_3x\", segmentation=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1PtN47ykwlx"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "for i in range(len(result)):\n",
        "    temp = pd.DataFrame(result[i][4], columns=result[i][4].keys())\n",
        "    temp = temp.T\n",
        "\n",
        "    images_per_batch = pd.Series([result[i][0]], index=[0])\n",
        "    learning_rate = pd.Series([result[i][1]], index=[0])\n",
        "    batch_size_per_image = pd.Series([result[i][2]], index=[0])\n",
        "\n",
        "    temp['images_per_batch'] = images_per_batch.values\n",
        "    temp['learning_rate'] = learning_rate.values\n",
        "    temp['batch_size_per_image'] = batch_size_per_image.values\n",
        "\n",
        "    df = pd.concat([df, temp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OE7spwvk1GB"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfqU2r4clIk1"
      },
      "outputs": [],
      "source": [
        "df.to_csv('result2/faster_rcnn_R_101_FPN_3x.csv', index=True, index_label=\"Result-type\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2aDclKttyWs"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv('result/faster_rcnn_R_101_FPN_3x.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yNng2sAtyWs"
      },
      "outputs": [],
      "source": [
        "dfbbox = get_best_result(df2, segmentation=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrQbuNzgtyWs"
      },
      "outputs": [],
      "source": [
        "dfbbox"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5QqUdNcjAEp"
      },
      "source": [
        "#### COCO-pretrained R50-FPN RetinaNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2y7WTpmntyWt"
      },
      "outputs": [],
      "source": [
        "images_per_batch = [2, 4, 8, 16, 32, 64]\n",
        "# images_per_batch = [2, 4, 8]\n",
        "learning_rate = [0.001, 0.00025, 0.0001, 0.000025, 0.00001]\n",
        "batch_size_per_image = [128, 256, 512] \n",
        "iteration = 1500\n",
        "num_classes = 4\n",
        "# num_classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-0hRgGejhgk"
      },
      "outputs": [],
      "source": [
        "init_model=\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbuSH_TKkp--"
      },
      "outputs": [],
      "source": [
        "result = []\n",
        "for ipb in images_per_batch:\n",
        "    for lr in learning_rate:\n",
        "        for bspi in batch_size_per_image:\n",
        "            cfg, test_result = train(dataset_name, \n",
        "                                     images_per_batch=ipb, \n",
        "                                     learning_rate=lr, \n",
        "                                     iteration=iteration, \n",
        "                                     batch_size_per_image=bspi, \n",
        "                                     num_classes=num_classes, \n",
        "                                     test=True, \n",
        "                                     test_dataset_name=val_dataset_name,\n",
        "                                     init_model=init_model,\n",
        "                                     retinaNet=True)\n",
        "\n",
        "            result.append([ipb, lr, bspi, cfg, test_result])\n",
        "            save_result(result=result, model_name=\"retinanet_R_50_FPN_3x\", segmentation=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsqBSZJHkxKF"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "for i in range(len(result)):\n",
        "    temp = pd.DataFrame(result[i][4], columns=result[i][4].keys())\n",
        "    temp = temp.T\n",
        "\n",
        "    images_per_batch = pd.Series([result[i][0]], index=[0])\n",
        "    learning_rate = pd.Series([result[i][1]], index=[0])\n",
        "    batch_size_per_image = pd.Series([result[i][2]], index=[0])\n",
        "\n",
        "    temp['images_per_batch'] = images_per_batch.values\n",
        "    temp['learning_rate'] = learning_rate.values\n",
        "    temp['batch_size_per_image'] = batch_size_per_image.values\n",
        "\n",
        "    df = pd.concat([df, temp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZE2HaApOk1wk"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzfJNzFytyWu"
      },
      "outputs": [],
      "source": [
        "df.to_csv('result2/retinanet_R_50_FPN_3x.csv', index=True, index_label=\"Result-type\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjxfLBu9tyWv"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv('result/retinanet_R_50_FPN_3x.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLrkH6A6tyWv"
      },
      "outputs": [],
      "source": [
        "dfbbox = get_best_result(df2, 5, segmentation=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBxllznmtyWw"
      },
      "outputs": [],
      "source": [
        "dfbbox"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyMsV4DsjHbo"
      },
      "source": [
        "#### COCO-pretrained R101-FPN RetinaNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lr0Q_Fi8tyWx"
      },
      "outputs": [],
      "source": [
        "images_per_batch = [2, 4, 8, 16, 32, 64]\n",
        "# images_per_batch = [2, 4, 8]\n",
        "learning_rate = [0.001, 0.00025, 0.0001, 0.000025, 0.00001]\n",
        "batch_size_per_image = [128, 256, 512] \n",
        "iteration = 1500\n",
        "num_classes = 4\n",
        "# num_classes = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-upsYLZbjhd6"
      },
      "outputs": [],
      "source": [
        "init_model=\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qr1Dkaa1jhKL"
      },
      "outputs": [],
      "source": [
        "result = []\n",
        "for ipb in images_per_batch:\n",
        "    for lr in learning_rate:\n",
        "        for bspi in batch_size_per_image:\n",
        "            cfg, test_result = train(dataset_name, \n",
        "                                     images_per_batch=ipb, \n",
        "                                     learning_rate=lr, \n",
        "                                     iteration=iteration, \n",
        "                                     batch_size_per_image=bspi, \n",
        "                                     num_classes=num_classes, \n",
        "                                     test=True, \n",
        "                                     test_dataset_name=val_dataset_name,\n",
        "                                     init_model=init_model,\n",
        "                                     retinaNet=True)\n",
        "\n",
        "            result.append([ipb, lr, bspi, cfg, test_result])\n",
        "            save_result(result=result, model_name=\"retinanet_R_101_FPN_3x\", segmentation=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORYhVbQBkyCH"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "for i in range(len(result)):\n",
        "    temp = pd.DataFrame(result[i][4], columns=result[i][4].keys())\n",
        "    temp = temp.T\n",
        "\n",
        "    images_per_batch = pd.Series([result[i][0]], index=[0])\n",
        "    learning_rate = pd.Series([result[i][1]], index=[0])\n",
        "    batch_size_per_image = pd.Series([result[i][2]], index=[0])\n",
        "\n",
        "    temp['images_per_batch'] = images_per_batch.values\n",
        "    temp['learning_rate'] = learning_rate.values\n",
        "    temp['batch_size_per_image'] = batch_size_per_image.values\n",
        "\n",
        "    df = pd.concat([df, temp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5ddbhmNk2e1"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hNesyfvlQbU"
      },
      "outputs": [],
      "source": [
        "df.to_csv('result2/retinanet_R_101_FPN_3x.csv', index=True, index_label=\"Result-type\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HG_tsOLityWy"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv('result/retinanet_R_101_FPN_3x.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygnac4RUtyWy"
      },
      "outputs": [],
      "source": [
        "dfbbox = get_best_result(df2, segmentation=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sz1R4_ghtyWz"
      },
      "outputs": [],
      "source": [
        "dfbbox"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}